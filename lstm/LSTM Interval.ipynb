{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import feats\n",
    "import constants\n",
    "import transactions\n",
    "import utils\n",
    "\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from imp import reload\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(constants.FEAT_DATA_DIR + 'up_interval_feat.pkl', 'rb') as f:\n",
    "    up_interval_feat = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 7 seconds\n",
    "up_interval_feat['X'] = up_interval_feat.p_purchase_interval.apply(lambda x:x[:-1])\n",
    "up_interval_feat['y'] = up_interval_feat.p_purchase_interval.apply(lambda x:x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 14 seconds\n",
    "max_seq_len = 90 # 90 # 10\n",
    "X = pad_sequences(up_interval_feat.X.values, maxlen=max_seq_len)\n",
    "y = up_interval_feat.y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.reshape(X, (X.shape[0], X.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regres_lstm(lstm_hidden_units, num_time_step, num_feat):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_hidden_units, return_sequences = True,\n",
    "                  input_shape = (num_time_step, num_feat)))\n",
    "    # model.add(LSTM(lstm_hidden_units, return_sequences = True,\n",
    "    #              input_shape = (num_time_step, num_feat)))\n",
    "    model.add(LSTM(lstm_hidden_units, return_sequences = False,\n",
    "                  input_shape = (num_time_step, num_feat)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = regres_lstm(32, 10, 1)\n",
    "model = regres_lstm(128, 90, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 90, 128)           66560     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 202,305\n",
      "Trainable params: 202,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath=\"./__lstm_cache__/\" + \"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1981178 samples, validate on 495295 samples\n",
      "Epoch 1/10\n",
      "1980928/1981178 [============================>.] - ETA: 0s - loss: 1638.9518Epoch 00000: loss improved from inf to 1638.99821, saving model to ./__lstm_cache__/weights-improvement-00-1638.9982.hdf5\n",
      "1981178/1981178 [==============================] - 2217s - loss: 1638.9982 - val_loss: 1640.9863\n",
      "Epoch 2/10\n",
      "1980928/1981178 [============================>.] - ETA: 0s - loss: 1635.8535Epoch 00001: loss improved from 1638.99821 to 1635.83705, saving model to ./__lstm_cache__/weights-improvement-01-1635.8371.hdf5\n",
      "1981178/1981178 [==============================] - 2117s - loss: 1635.8371 - val_loss: 1640.9780\n",
      "Epoch 3/10\n",
      "1980928/1981178 [============================>.] - ETA: 0s - loss: 1635.7965Epoch 00002: loss improved from 1635.83705 to 1635.83570, saving model to ./__lstm_cache__/weights-improvement-02-1635.8357.hdf5\n",
      "1981178/1981178 [==============================] - 2182s - loss: 1635.8357 - val_loss: 1640.9985\n",
      "Epoch 4/10\n",
      " 182784/1981178 [=>............................] - ETA: 2168s - loss: 1636.5614"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=256, epochs=10, validation_split=0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regres_lstm_pred(model, X, y):\n",
    "    y_pred = model.predict(X_test).flatten()\n",
    "    y_persis = X_test[:, -1].flatten()\n",
    "    res = pd.DataFrame({'y_pred':y_pred, 'y_persis':y_persis, 'y_gold':y})\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_baseline = X_test[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_test = pd.DataFrame({'y_pred':y_pred.flatten(), 'y_baseline':y_baseline.flatten(), 'y_test':y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse_lstm = sqrt(mean_squared_error(res_test.y_test, res_test.y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse_persis = sqrt(mean_squared_error(res_test.y_test, res_test.y_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"RMSE of Persistence Model is %f \\nRMSE of LSTM Model is %f\"%(rmse_persis, rmse_lstm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('./__lstm_cache__/weights-improvement-05-1514.2298.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = regres_lstm_pred(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"RMSE of Persistence Model is %f \\nRMSE of LSTM Model is %f\" % \n",
    "      (cal_rmse(res.y_gold, res.y_persis), cal_rmse(res.y_gold, res.y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict all orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_seq_len = 10\n",
    "X_all = pad_sequences(up_interval_feat.up_interval.values, maxlen=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_all = np.reshape(X_all, (X_all.shape[0], X_all.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#24 minutes\n",
    "y_all = model.predict(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./y_all.pkl', 'wb') as f:\n",
    "    pickle.dump(y_all, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./y_all.pkl', 'rb') as f:\n",
    "    y_all = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate with train orders\n",
    "- y_all（u,p)在prior中出现至少两次，即用户至少购买两次商品，过滤掉只购买一次的商品\n",
    "- 在prior订单中，只购买一次的商品如何预测呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tle = transactions.TransLogExtractor(constants.RAW_DATA_DIR, constants.FEAT_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "order_products_train = tle.get_orders_items('train')\n",
    "\n",
    "order_products_prior = tle.get_orders_items('prior')\n",
    "\n",
    "orders = tle.get_orders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users_orders = tle.get_users_orders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(constants.FEAT_DATA_DIR + 'interact_feat.pkl', 'rb') as f:\n",
    "    up_interact_feat = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(up_interact_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(up_interval_feat), len(up_latest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "up_interval = up_interval_feat[['user_id', 'product_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "up_interval['pred'] = y_all.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "up_interval = pd.merge(up_interval, \n",
    "                       up_interact_feat[['user_id', 'product_id', 'up_days_to_last']], \n",
    "                       on = ['user_id', 'product_id'], \n",
    "                       how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "up_interval['delta'] = up_interval['pred'] - up_interval['up_days_to_last']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "up_interval['abs_delta'] = up_interval['delta'].apply(abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "up_interval.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "up_interval.columns = ['user_id', 'product_id', 'pred', 'up_days_to_last', 'up_delta',\n",
    "       'up_abs_delta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "up_delta = up_interval[['user_id', 'product_id', 'up_delta', 'up_abs_delta']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(constants.FEAT_DATA_DIR + 'up_delta.pkl', 'wb') as f:\n",
    "    pickle.dump(up_delta, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(constants.FEAT_DATA_DIR + 'label.pkl', 'rb') as f:\n",
    "    label = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "up_interval = pd.merge(up_interval, label, on = ['user_id', 'product_id'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "up_interval['label'] = up_interval.label.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "up_interval.label.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = up_interval.abs_diff.values\n",
    "X = np.reshape(X, (X.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = up_interval.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
