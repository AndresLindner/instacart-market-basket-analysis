{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import feats\n",
    "import constants\n",
    "import transactions\n",
    "\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AucComputer(keras.callbacks.Callback):\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.validation_data[0], batch_size=2048)\n",
    "        logs['val_auc'] = roc_auc_score(self.validation_data[1], y_pred)\n",
    "        print('epoch {}, val auc {}'.format(epoch, logs['val_auc']))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Leak Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(constants.FEAT_DATA_DIR + 'up_airr_sym.pkl', 'rb') as f:\n",
    "    up_airr_sym = pickle.load(f)\n",
    "tle = transactions.TransLogExtractor(constants.RAW_DATA_DIR, constants.FEAT_DATA_DIR)\n",
    "train_orders = tle.get_orders()\n",
    "\n",
    "uid_train = train_orders[train_orders.eval_set == 'train'][['user_id']].drop_duplicates()\n",
    "uid_test = train_orders[train_orders.eval_set == 'test'][['user_id']].drop_duplicates()\n",
    "del train_orders\n",
    "\n",
    "up_airr_sym_train = up_airr_sym[up_airr_sym.user_id.isin(uid_train.user_id)]\n",
    "up_airr_sym_test = up_airr_sym[up_airr_sym.user_id.isin(uid_test.user_id)]\n",
    "\n",
    "up_airr_sym_train = pd.merge(up_airr_sym_train, tle.craft_label(), \n",
    "                             on=['user_id','product_id'], how='left')\n",
    "up_airr_sym_train.label.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "up_airr_sym_train = shuffle(up_airr_sym_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "up_airr_sym_train['len'] = up_airr_sym_train.up_airr_sym.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49 s, sys: 3.02 s, total: 52 s\n",
      "Wall time: 51.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_seq_len = 99\n",
    "X = pad_sequences(up_airr_sym_train.up_airr_sym.values, maxlen=max_seq_len)\n",
    "y = up_airr_sym_train.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sym_set_size = 480\n",
    "embed_vec_len = 32\n",
    "hidden_units = 256\n",
    "def embed_lstm(sym_set_size, embed_vec_len, max_seq_len, hidden_units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(sym_set_size, embed_vec_len, input_length=max_seq_len))\n",
    "    model.add(LSTM(hidden_units, return_sequences = True))\n",
    "    model.add(LSTM(hidden_units))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = embed_lstm(sym_set_size, embed_vec_len, max_seq_len, hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 99, 32)            15360     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 99, 256)           295936    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 935,425\n",
      "Trainable params: 935,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath=\"./__lstm_cache__/\" + \"lstm-symbol-{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "auc_computer = AucComputer()\n",
    "callbacks_list = [checkpoint, auc_computer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6644133 samples, validate on 135595 samples\n",
      "Epoch 1/100\n",
      "6643712/6644133 [============================>.] - ETA: 0s - loss: 0.2792 - acc: 0.9029Epoch 00000: val_loss improved from inf to 0.27488, saving model to ./__lstm_cache__/lstm-symbol-00-0.2749.hdf5\n",
      "epoch 0, val auc 0.7697543970380116\n",
      "6644133/6644133 [==============================] - 2072s - loss: 0.2792 - acc: 0.9029 - val_loss: 0.2749 - val_acc: 0.9032\n",
      "Epoch 2/100\n",
      "6643712/6644133 [============================>.] - ETA: 0s - loss: 0.2756 - acc: 0.9033Epoch 00001: val_loss improved from 0.27488 to 0.27465, saving model to ./__lstm_cache__/lstm-symbol-01-0.2746.hdf5\n",
      "epoch 1, val auc 0.7705183616409019\n",
      "6644133/6644133 [==============================] - 2024s - loss: 0.2756 - acc: 0.9033 - val_loss: 0.2746 - val_acc: 0.9033\n",
      "Epoch 3/100\n",
      "6643712/6644133 [============================>.] - ETA: 0s - loss: 0.2748 - acc: 0.9034Epoch 00002: val_loss improved from 0.27465 to 0.27427, saving model to ./__lstm_cache__/lstm-symbol-02-0.2743.hdf5\n",
      "epoch 2, val auc 0.7708393249016537\n",
      "6644133/6644133 [==============================] - 1839s - loss: 0.2748 - acc: 0.9034 - val_loss: 0.2743 - val_acc: 0.9032\n",
      "Epoch 4/100\n",
      "6643712/6644133 [============================>.] - ETA: 0s - loss: 0.2745 - acc: 0.9034Epoch 00003: val_loss improved from 0.27427 to 0.27416, saving model to ./__lstm_cache__/lstm-symbol-03-0.2742.hdf5\n",
      "epoch 3, val auc 0.7707677718528326\n",
      "6644133/6644133 [==============================] - 1817s - loss: 0.2745 - acc: 0.9034 - val_loss: 0.2742 - val_acc: 0.9036\n",
      "Epoch 5/100\n",
      "6643712/6644133 [============================>.] - ETA: 0s - loss: 0.2743 - acc: 0.9035Epoch 00004: val_loss improved from 0.27416 to 0.27391, saving model to ./__lstm_cache__/lstm-symbol-04-0.2739.hdf5\n",
      "epoch 4, val auc 0.7710791899243711\n",
      "6644133/6644133 [==============================] - 1819s - loss: 0.2743 - acc: 0.9035 - val_loss: 0.2739 - val_acc: 0.9036\n",
      "Epoch 6/100\n",
      "6643712/6644133 [============================>.] - ETA: 0s - loss: 0.2741 - acc: 0.9035Epoch 00005: val_loss improved from 0.27391 to 0.27382, saving model to ./__lstm_cache__/lstm-symbol-05-0.2738.hdf5\n",
      "epoch 5, val auc 0.771316827602849\n",
      "6644133/6644133 [==============================] - 1800s - loss: 0.2741 - acc: 0.9035 - val_loss: 0.2738 - val_acc: 0.9038\n",
      "Epoch 7/100\n",
      "6643712/6644133 [============================>.] - ETA: 0s - loss: 0.2740 - acc: 0.9035Epoch 00006: val_loss improved from 0.27382 to 0.27359, saving model to ./__lstm_cache__/lstm-symbol-06-0.2736.hdf5\n",
      "epoch 6, val auc 0.7716736217322547\n",
      "6644133/6644133 [==============================] - 1800s - loss: 0.2740 - acc: 0.9035 - val_loss: 0.2736 - val_acc: 0.9035\n",
      "Epoch 8/100\n",
      "6643712/6644133 [============================>.] - ETA: 0s - loss: 0.2740 - acc: 0.9035Epoch 00007: val_loss did not improve\n",
      "epoch 7, val auc 0.7714203818676213\n",
      "6644133/6644133 [==============================] - 1798s - loss: 0.2740 - acc: 0.9035 - val_loss: 0.2736 - val_acc: 0.9038\n",
      "Epoch 9/100\n",
      "6555648/6644133 [============================>.] - ETA: 24s - loss: 0.2739 - acc: 0.9036"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          batch_size=2048, \n",
    "          epochs=100, \n",
    "          validation_split=0.02, \n",
    "          callbacks=callbacks_list,\n",
    "          class_weight={0:1, 1:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 10 s, total: 1min 14s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model.predict(X_test, batch_size=4028)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test auc 0.7710464231968976\n"
     ]
    }
   ],
   "source": [
    "print('test auc {}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
